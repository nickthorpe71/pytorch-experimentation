import torch
import torch.nn as nn

import torchvision
import torchvision.transforms as transforms
# import matplotlib.animation
# import matplotlib.pyplot as plt

# import numpy as np
import os
# from IPython.display import HTML

from training_stats_manager import TrainingStatsManager

# for consistancy on each run
torch.manual_seed(1)
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True

# Device configuration (use GPU)
device = torch.device(
    'cuda:0' if torch.cuda.is_available() else 'cpu'
)
print(device)

# Hyper-parameters
batch_size = 128
num_epochs = 5
image_size = 64
num_channels = 1
z_size = 100
num_g_filters = 64
num_d_filters = 64
lr = 0.0002
betas = (0.5, 0.999)
num_workers = 1


# download and prepare the MNIST dataset
dataset = torchvision.datasets.MNIST(
    root=os.path.relpath('data/mnist'),
    download=True,
    transform=transforms.Compose([
        transforms.Resize(image_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.5), std=(0.5))
    ])
)

# load the dataset
dataloader = torch.utils.data.DataLoader(
    dataset=dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=num_workers
)

# plot some images from the training set to get a quick visualization
# real_batch = next(iter(dataloader))
# images, labels = real_batch

# grid = torchvision.utils.make_grid(images, nrow=10, normalize=True)

# plt.figure(figsize=(10, 10))
# plt.axis("off")
# plt.imshow(grid.permute(1, 2, 0))
# plt.savefig('sample.png')


def weights_init(module):
    classname = module.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(module.weight.data, 0.0, 0.02)


# ------ GENERATOR ------ #
# As input, the generator accepts batches of noise vectors,
# each generally referred to as z and of length 100, with values
# randomly sampled from a normal distribution. The output of the
# generator is a num_channels x 64 x 64 image. This is an image
# with num_channels color channels (RGB) with a height and width
# of 64 pixels.

netG = nn.Sequential(
    nn.ConvTranspose2d(
        in_channels=z_size,
        out_channels=num_g_filters * 8,
        kernel_size=4,
        stride=1,
        padding=0,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_g_filters * 8),
    nn.ReLU(inplace=True),

    nn.ConvTranspose2d(
        in_channels=num_g_filters * 8,
        out_channels=num_g_filters * 4,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_g_filters * 4),
    nn.ReLU(inplace=True),

    nn.ConvTranspose2d(
        in_channels=num_g_filters * 4,
        out_channels=num_g_filters * 2,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_g_filters * 2),
    nn.ReLU(inplace=True),

    nn.ConvTranspose2d(
        in_channels=num_g_filters * 2,
        out_channels=num_g_filters,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_g_filters),
    nn.ReLU(inplace=True),

    nn.ConvTranspose2d(
        in_channels=num_g_filters,
        out_channels=num_channels,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.Tanh()
)

# initialize the generator and apply the weights_init function
netG = netG.to(device)
# apply recursively applies the weights_init function to every
# PyTorch submodule in the network
netG.apply(weights_init)


# ------ DISCRIMINATOR ------ #
# The discriminator is a convolutional neural network that accepts
# images of size 3 x 64 x 64 as input, and outputs the probability
# that it assigns to the image being real, as opposed to being fake
# (generated by the generator).

netD = nn.Sequential(
    nn.Conv2d(
        in_channels=num_channels,
        out_channels=num_d_filters,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.LeakyReLU(negative_slope=0.2, inplace=True),

    nn.Conv2d(
        in_channels=num_d_filters,
        out_channels=num_d_filters * 2,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_d_filters * 2),
    nn.LeakyReLU(negative_slope=0.2, inplace=True),

    nn.Conv2d(
        in_channels=num_d_filters * 2,
        out_channels=num_d_filters * 4,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_d_filters * 4),
    nn.LeakyReLU(negative_slope=0.2, inplace=True),

    nn.Conv2d(
        in_channels=num_d_filters * 4,
        out_channels=num_d_filters * 8,
        kernel_size=4,
        stride=2,
        padding=1,
        bias=False
    ),
    nn.BatchNorm2d(num_features=num_d_filters * 8),
    nn.LeakyReLU(negative_slope=0.2, inplace=True),

    nn.Conv2d(
        in_channels=num_d_filters * 8,
        out_channels=1,
        kernel_size=4,
        stride=1,
        padding=0,
        bias=False
    ),
    nn.Sigmoid()
)

# initialize the discriminator and apply the weights_init function
netD = netD.to(device)
# apply recursively applies the weights_init function to every
# PyTorch submodule in the network
netD.apply(weights_init)


# initialize the loss function
bce_loss = nn.BCELoss()


def discriminator_loss(real_output, fake_output):
    real_loss = bce_loss(real_output, torch.ones_like(real_output))
    fake_loss = bce_loss(fake_output, torch.zeros_like(fake_output))
    return real_loss + fake_loss


def generator_loss(fake_output):
    return bce_loss(fake_output, torch.ones_like(fake_output))


# initialize the optimizers
d_optimizer = torch.optim.Adam(netD.parameters(), lr=lr, betas=betas)
g_optimizer = torch.optim.Adam(netG.parameters(), lr=lr, betas=betas)

# to track training progress
g_losses = []
d_losses = []

fixed_noise = torch.randn(64, z_size, 1, 1, device=device)
fake_img_grids = []

with torch.no_grad():
    fixed_fakes = netG(fixed_noise).detach().cpu()
fake_img_grids.append(torchvision.utils.make_grid(
    fixed_fakes, padding=2, normalize=True))

stats = TrainingStatsManager(batches_per_epoch=len(dataloader))
stats.begin_run()

for epoch in range(num_epochs):
    stats.begin_epoch()

    for batch in dataloader:

        # TRAIN DISCRIMINATOR
        netD.zero_grad()

        # in each batch, index 0 is the image data
        # and index 1 is the corrisponding label
        real_images = batch[0].to(device)
        real_output = netD(real_images)

        noise = torch.randn(real_images.size(0), z_size, 1, 1).to(device)
        fake_images = netG(noise)
        fake_output = netD(fake_images.detach())

        d_loss = discriminator_loss(real_output, fake_output)
        d_loss.backward()  # calculate gradients
        d_optimizer.step()  # update weights

        stats.track('real_mean', real_output.mean().item())
        stats.track('fake_mean1', fake_output.mean().item())
        stats.track('d_loss', d_loss.item())

        # TRAIN GENERATOR
        netG.zero_grad()
        fake_output = netD(fake_images)
        g_loss = generator_loss(fake_output)
        g_loss.backward()
        g_optimizer.step()

        stats.track('g_loss', g_loss.item())
        stats.track('fake_mean2', fake_output.mean().item())
        stats.progress.update()

    # Display training stats
